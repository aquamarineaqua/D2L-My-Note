{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "torch.set_printoptions(precision=8)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充（扩展）与复制与限幅\n",
    "填充（扩展）一般指往外填0<br>\n",
    "复制指在维度层面复制数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扩展（tensorflow）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32, 32, 3)\n",
      "tf.Tensor(\n",
      "[[[[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [-1.185166    1.7797291  -0.7389856 ]\n",
      "   ...\n",
      "   [ 0.30852383  0.78451246 -2.937814  ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.02745774 -0.24303909  1.3584884 ]\n",
      "   ...\n",
      "   [-0.45670113  2.611427   -1.2022815 ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [-2.152822    1.137188    0.40584236]\n",
      "   ...\n",
      "   [-0.9090948   1.2982136   1.4518623 ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.95304877  0.7083174  -2.124863  ]\n",
      "   ...\n",
      "   [-0.6021546   0.4702971   0.39343455]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ...\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.          0.          0.        ]]]], shape=(2, 32, 32, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "b = tf.random.normal((2,28,28,3))\n",
    "# 扩展为[2,32,32,3]\n",
    "b_pad = tf.pad(b, [[0,0], [2,2], [2,2], [0,0]])\n",
    "# pad方法的第二个参数：传入一个嵌套List，指定每个维度的扩展方案，比如第二个维度为[2,2]，意为向左边扩展2个，向右边扩展2个。\n",
    "print(b_pad.shape)\n",
    "print(b_pad)  # 可以看到默认扩展的是0值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扩展（pytorch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,28,28,3)\n",
    "# 扩展为[2,32,32,3]\n",
    "\n",
    "# 在pytorch中，使用：torch.nn.functional.pad(input, pad, mode='constant', value=0)\n",
    "# 文档地址：https://pytorch.org/docs/1.2.0/nn.functional.html?highlight=pad#torch.nn.functional.pad\n",
    "# pad方法的第二个参数：传入一个Tuple，指定每个维度的扩展方案。\n",
    "\n",
    "import torch.nn.functional as F\n",
    "a_pad = F.pad(a, (0,0, 2,2, 2,2))\n",
    "# 可以看到第二个参数，传入的各个维度的扩展个数，两个值为一对；从左到右依次对应为倒数第1个维度，倒数第2个维度...往后类推。\n",
    "# 比如我传入的(0,0, 2,2, 2,2)，意为倒数第1个维度左边扩0，右边括0；倒数第2个维度左边扩2，右边扩2；倒数第3个维度左边扩2，右边扩2\n",
    "\n",
    "print(a_pad.shape) \n",
    "# 默认扩展0值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充（tensorflow）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.08872307  0.07705077 -0.9532041  -0.83272016  0.5590754 ]\n",
      " [ 1.0346495   2.1215284  -0.6710165   0.729277    0.02806538]], shape=(2, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.08872307  0.07705077 -0.9532041  -0.83272016  0.5590754 ]\n",
      " [ 1.0346495   2.1215284  -0.6710165   0.729277    0.02806538]\n",
      " [-0.08872307  0.07705077 -0.9532041  -0.83272016  0.5590754 ]\n",
      " [ 1.0346495   2.1215284  -0.6710165   0.729277    0.02806538]], shape=(4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 填充即在指定维度层面复制数据，注意复制数据是实际意义上的扩充数据\n",
    "\n",
    "b = tf.random.normal([2,5])\n",
    "print(b)\n",
    "\n",
    "b = tf.tile(b, multiples=[2, 1])  # 第二个参数multiple，指定各个维度的复制倍数。比如这里指第1个维度复制为2倍，第二个维度为1倍（即不变）\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充（pytorch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.12374803, -1.24584711,  0.14674927,  0.00777690,  2.77004242],\n",
      "        [-0.12842306, -0.71658367,  0.88788193, -0.53651679, -1.25461745]])\n",
      "tensor([[ 0.12374803, -1.24584711,  0.14674927,  0.00777690,  2.77004242],\n",
      "        [-0.12842306, -0.71658367,  0.88788193, -0.53651679, -1.25461745],\n",
      "        [ 0.12374803, -1.24584711,  0.14674927,  0.00777690,  2.77004242],\n",
      "        [-0.12842306, -0.71658367,  0.88788193, -0.53651679, -1.25461745]])\n"
     ]
    }
   ],
   "source": [
    "# 填充即在维度层面复制数据，注意复制维度数据是实际意义上的扩充数据\n",
    "a = torch.randn(2,5)\n",
    "print(a)\n",
    "\n",
    "# 在pytorch 1.2中没有tile方法，可用repeat方法\n",
    "a = a.repeat(2,1)    # 直接对tensor使用repeat方法，传入的参数即指定各个维度的复制倍数。比如这里指第1个维度复制为2倍，第二个维度为1倍（即不变）\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 限幅（tensorflow）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "设定下限幅效果： tf.Tensor([2 2 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "设定上限幅效果： tf.Tensor([0 1 2 3 4 5 6 7 7 7], shape=(10,), dtype=int32)\n",
      "设定上下限幅效果： tf.Tensor([3 3 3 3 4 5 6 7 7 7], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 对数值大小进行约束\n",
    "\n",
    "# 下限幅：maximum， 上限幅：minimum（这里有点反直觉）\n",
    "b = tf.range(10)\n",
    "print(b)\n",
    "print('设定下限幅效果：', tf.maximum(b, 2))   # 下限幅为maximum，可以理解为最大的最小值\n",
    "print('设定上限幅效果：', tf.minimum(b, 7))   # 上限幅为minimum，可以理解为最小的最大值\n",
    "print('设定上下限幅效果：', tf.clip_by_value(b, 3, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 限幅（pytorch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "设定下限幅效果： tensor([ 2.,  2.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "设定上限幅效果： tensor([0., 1., 2., 3., 4., 5., 6., 7., 7., 7., 7.])\n",
      "设定上下限幅效果： tensor([2., 2., 2., 3., 4., 5., 6., 7., 7., 7., 7.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\takedachia\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# 对数据大小进行约束\n",
    "\n",
    "# 限幅：torch.clamp\n",
    "a = torch.range(0, 10)\n",
    "print(a)\n",
    "print('设定下限幅效果：', torch.clamp(a, min=2))   # 只设定min的话，即设下限幅\n",
    "print('设定上限幅效果：', torch.clamp(a, max=7))   # 只设定max的话，即设上限幅\n",
    "print('设定上下限幅效果：', torch.clamp(a, min=2, max=7))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58edbf06b447562b2f859b4d256e1fe9b5ec2dc8d59984181fb6f62f1d7242b1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
